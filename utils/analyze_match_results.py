#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€åŒ¹é…ç»“æœå‡†ç¡®ç‡ä¸åŒ¹é…æ•°ç»Ÿè®¡è„šæœ¬
åˆ†æ MultiModal_Output ç›®å½•ä¸‹çš„åŒ¹é…ç»“æœ

åŠŸèƒ½ç‰¹æ€§:
- è®¡ç®—åŒ¹é…å‡†ç¡®ç‡ï¼ˆæ”¯æŒå¤šä¸ªåƒç´ è¯¯å·®é˜ˆå€¼ï¼‰
- ç»Ÿè®¡RANSACç®—æ³•å‰”é™¤åçš„æœ‰æ•ˆåŒ¹é…æ•°
- è®¡ç®—åŒ¹é…ä¿ç•™ç‡ï¼ˆæœ‰æ•ˆåŒ¹é…æ•°/æ€»åŒ¹é…æ•°ï¼‰
- æ”¯æŒæ’é™¤ç‰¹å®šæ¨¡æ€
- ç”Ÿæˆè¯¦ç»†çš„ExcelæŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
1. åˆ†ææ‰€æœ‰æ¨¡æ€ï¼ˆä¼ ç»Ÿæ–¹æ³•ï¼Œå‡è®¾è§†è§’ä¸€è‡´ï¼‰:
   python analyze_match_results.py

2. ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾åˆ†æï¼ˆç”¨äºé€è§†å˜æ¢å¢å¼ºçš„æ•°æ®ï¼‰:
   python analyze_match_results.py --use_perspective_label

3. æ’é™¤OpticalFlowæ¨¡æ€å¹¶ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾:
   python analyze_match_results.py --exclude_modalities OpticalFlow --use_perspective_label

4. æ’é™¤å¤šä¸ªæ¨¡æ€:
   python analyze_match_results.py --exclude_modalities OpticalFlow FreqDomain

5. æŒ‡å®šè‡ªå®šä¹‰è¾“å‡ºç›®å½•å’ŒExcelæ–‡ä»¶å:
   python analyze_match_results.py --output_dir /path/to/output --excel_output custom_results.xlsx --use_perspective_label

6. æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯:
   python analyze_match_results.py --help

è¾“å‡ºExcelæ–‡ä»¶åŒ…å«çš„å·¥ä½œè¡¨:
- è¯¦ç»†ç»“æœ_å‡†ç¡®ç‡: æ¯ä¸ªåœºæ™¯å’Œæ¨¡æ€çš„å‡†ç¡®ç‡è¯¦ç»†æ•°æ®
- è¯¦ç»†ç»“æœ_åŒ¹é…æ•°: æ¯ä¸ªåœºæ™¯å’Œæ¨¡æ€çš„åŒ¹é…æ•°è¯¦ç»†æ•°æ®ï¼ˆåŒ…å«ä¿ç•™ç‡ï¼‰
- åœºæ™¯å¹³å‡å‡†ç¡®ç‡: æ¯ä¸ªåœºæ™¯çš„å¹³å‡å‡†ç¡®ç‡
- æ¨¡æ€å¹³å‡å‡†ç¡®ç‡: æ¯ä¸ªæ¨¡æ€çš„å¹³å‡å‡†ç¡®ç‡
- å…¨å±€å¹³å‡å‡†ç¡®ç‡: æ‰€æœ‰æ•°æ®çš„å…¨å±€å¹³å‡å‡†ç¡®ç‡
- åœºæ™¯å¹³å‡åŒ¹é…æ•°: æ¯ä¸ªåœºæ™¯çš„å¹³å‡åŒ¹é…æ•°
- æ¨¡æ€å¹³å‡åŒ¹é…æ•°: æ¯ä¸ªæ¨¡æ€çš„å¹³å‡åŒ¹é…æ•°
- å…¨å±€å¹³å‡åŒ¹é…æ•°: æ‰€æœ‰æ•°æ®çš„å…¨å±€å¹³å‡åŒ¹é…æ•°
"""

import os
import glob
import pandas as pd
import numpy as np
from collections import defaultdict
from typing import Dict, List, Tuple
import json
import cv2

use_pt_level = False
video_root = "/mnt/mDisk2/APIDIS_P/mp4"

def get_video_resolution_from_match_path(match_path: str, video_root: str = video_root) -> tuple:
    """
    ä»åŒ¹é…ç»“æœè·¯å¾„ä¸­æå–åœºæ™¯åï¼Œè¯»å–å¯¹åº”è§†é¢‘çš„åˆ†è¾¨ç‡ã€‚
    
    Args:
        match_path: åŒ¹é…ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ MultiModal_Output_ransac_5_05/K1/...
        video_root: è§†é¢‘æ ¹ç›®å½•ï¼Œé»˜è®¤ video_root
    
    Returns:
        (width, height) åˆ†è¾¨ç‡å…ƒç»„ï¼›å¦‚æœæ‰¾ä¸åˆ°è§†é¢‘æˆ–è¯»å–å¤±è´¥ï¼Œè¿”å› None
    """
    # 1. æå–åœºæ™¯å
    parts = os.path.normpath(match_path).split(os.sep)
    try:
        k_index = parts.index('MultiModal_Output') + 1
        scene_name = parts[k_index]  # æ¯”å¦‚ "K1"
    except (ValueError, IndexError):
        print(f"âŒ æ— æ³•ä»è·¯å¾„ä¸­æå–åœºæ™¯å: {match_path}")
        return None

    # 2. æ„é€ è§†é¢‘è·¯å¾„
    video_file = os.path.join(video_root, f"{scene_name}.mp4")
    if not os.path.exists(video_file):
        print(f"âŒ è§†é¢‘æ–‡ä»¶æœªæ‰¾åˆ°: {video_file}")
        return None

    # 3. ä½¿ç”¨ OpenCV è·å–è§†é¢‘åˆ†è¾¨ç‡
    cap = cv2.VideoCapture(video_file)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_file}")
        return None

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    print(f"ğŸ¥ è§†é¢‘ {scene_name}.mp4 åˆ†è¾¨ç‡: {width} x {height}")
    return (width, height)


def patch_id_to_coords(patch_id: int, patch_size: int, image_width: int) -> Tuple[float, float]:
    """
    å°† patch ID è½¬æ¢ä¸ºå›¾åƒåæ ‡ï¼ˆä¸­å¿ƒç‚¹ï¼‰
    - patch_size: 8, 16, 32, ...
    - image_width: å›¾åƒå®½åº¦ï¼ˆåƒç´ ï¼‰
    """
    cols_per_row = image_width // patch_size
    row = patch_id // cols_per_row
    col = patch_id % cols_per_row
    x = col * patch_size + patch_size / 2
    y = row * patch_size + patch_size / 2
    return (x, y)

def load_match_ids_from_txt(file_path: str) -> List[Tuple[int, int]]:
    """
    è¯»å–åŒ¹é…txtæ–‡ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    - ç¬¬ä¸€è¡Œæ˜¯åŒ¹é…æ•°é‡ï¼ˆæ•´æ•°ï¼‰
    - åç»­æ¯è¡Œæœ‰3ä¸ªæ•°å­—ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼Œæ ¼å¼å¦‚ id1 id2 value
    è¿”å›åªæå– (id1, id2) çš„åˆ—è¡¨
    """
    matches = []
    print(f"ğŸ“„ è¯»å–åŒ¹é…æ–‡ä»¶: {file_path}")
    with open(file_path, 'r') as f:
        lines = f.readlines()
        if not lines:
            return matches
        
        try:
            total_matches = int(lines[0].strip())  # è¯»å–ç¬¬ä¸€è¡ŒåŒ¹é…æ•°é‡
        except:
            total_matches = None  # å¦‚æœç¬¬ä¸€è¡Œä¸æ˜¯æ•´æ•°ä¹Ÿä¸æŠ¥é”™ï¼Œå¿½ç•¥
        
        for line in lines[1:]:  # è·³è¿‡ç¬¬ä¸€è¡Œ
            try:
                parts = line.strip().split()  # é»˜è®¤æŒ‰ç©ºç™½åˆ†å‰²
                if len(parts) < 2:
                    continue
                id1, id2 = int(parts[0]), int(parts[1])
                matches.append((id1, id2))
            except:
                continue
    
    return matches


def load_relative_transform_matrix(match_file_path: str) -> np.ndarray:
    """
    åŠ è½½ç›¸å¯¹é€è§†å˜æ¢çŸ©é˜µä½œä¸ºæ ‡ç­¾
    
    Args:
        match_file_path: åŒ¹é…æ–‡ä»¶è·¯å¾„
        
    Returns:
        3x3ç›¸å¯¹é€è§†å˜æ¢çŸ©é˜µï¼Œå¦‚æœæœªæ‰¾åˆ°æˆ–åŠ è½½å¤±è´¥è¿”å›None
    """
    # ä»åŒ¹é…æ–‡ä»¶è·¯å¾„æ¨æ–­ç›¸å¯¹å˜æ¢çŸ©é˜µè·¯å¾„
    # åŒ¹é…æ–‡ä»¶è·¯å¾„ä¾‹å¦‚: .../A1/FreqDomain_vs_MotionThermal/MatchResult/List/.../8x8.txt
    # ç›¸å¯¹å˜æ¢çŸ©é˜µè·¯å¾„: .../A1/FreqDomain_vs_MotionThermal/relative_transform_matrix.npy
    
    # æ‰¾åˆ°åŒ…å« "_vs_" çš„ç›®å½•å±‚çº§
    current_path = match_file_path
    modality_pair_dir = None
    
    while current_path and current_path != os.path.dirname(current_path):
        current_path = os.path.dirname(current_path)
        dir_name = os.path.basename(current_path)
        
        if '_vs_' in dir_name:
            modality_pair_dir = current_path
            break
    
    if not modality_pair_dir:
        print(f"âŒ æ— æ³•æ‰¾åˆ°åŒ…å«'_vs_'çš„ç›®å½•å±‚çº§: {match_file_path}")
        return None
        
    matrix_path = os.path.join(modality_pair_dir, 'relative_transform_matrix.npy')
    
    try:
        if os.path.exists(matrix_path):
            matrix = np.load(matrix_path)
            if matrix.shape == (3, 3):
                print(f"âœ… åŠ è½½ç›¸å¯¹å˜æ¢çŸ©é˜µ: {matrix_path}")
                return matrix
            else:
                print(f"âŒ ç›¸å¯¹å˜æ¢çŸ©é˜µç»´åº¦é”™è¯¯: {matrix.shape}")
                return None
        else:
            print(f"âš ï¸ ç›¸å¯¹å˜æ¢çŸ©é˜µæ–‡ä»¶æœªæ‰¾åˆ°: {matrix_path}")
            return None
    except Exception as e:
        print(f"âŒ åŠ è½½ç›¸å¯¹å˜æ¢çŸ©é˜µå¤±è´¥: {matrix_path} - {e}")
        return None


def calculate_accuracy(match_file_path: str, use_perspective_label: bool = False) -> Dict[str, any]:
    """
    ä½¿ç”¨RANSACè¯„ä¼°åŒ¹é…å‡†ç¡®ç‡ï¼Œå¹¶ç»Ÿè®¡å‰”é™¤åçš„åŒ¹é…æ•°ã€‚
    æ”¯æŒä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾çŸ©é˜µè®¡ç®—å‡†ç¡®æ€§ã€‚

    Args:
        match_file_path: åŒ¹é…æ–‡ä»¶è·¯å¾„
        use_perspective_label: æ˜¯å¦ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾çŸ©é˜µè®¡ç®—å‡†ç¡®æ€§

    Returns:
        Dict containing:
        - 'accuracy': Dict[int, float] - key æ˜¯åƒç´ è¯¯å·®é˜ˆå€¼ï¼Œvalue æ˜¯è¯¥é˜ˆå€¼ä¸‹çš„å‡†ç¡®ç‡
        - 'match_count': int - RANSACç®—æ³•å‰”é™¤åçš„æœ‰æ•ˆåŒ¹é…æ•°
        - 'total_matches': int - åŸå§‹æ€»åŒ¹é…æ•°
        - 'use_perspective_label': bool - æ˜¯å¦ä½¿ç”¨äº†é€è§†å˜æ¢æ ‡ç­¾
        - 'perspective_available': bool - é€è§†å˜æ¢æ ‡ç­¾æ˜¯å¦å¯ç”¨
    """
    # æ ¹æ® use_pt_level ç¡®å®šè¦ä½¿ç”¨çš„é˜ˆå€¼
    if use_pt_level:
        thresholds = [4, 8, 12, 16, 20]
    else:
        thresholds = list(range(1, 11))
    
    # é”™è¯¯æƒ…å†µä¸‹è¿”å›çš„é»˜è®¤å‡†ç¡®ç‡å­—å…¸
    default_accuracy = {k: 0.0 for k in thresholds}
    
    # å°è¯•åŠ è½½ç›¸å¯¹é€è§†å˜æ¢çŸ©é˜µ
    relative_transform_matrix = None
    perspective_available = False
    if use_perspective_label:
        relative_transform_matrix = load_relative_transform_matrix(match_file_path)
        perspective_available = relative_transform_matrix is not None
        if not perspective_available:
            print(f"âš ï¸ å¯ç”¨é€è§†å˜æ¢æ ‡ç­¾ä½†æœªæ‰¾åˆ°çŸ©é˜µæ–‡ä»¶ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
    
    try:
        matches = load_match_ids_from_txt(match_file_path)
        total_matches = len(matches)
        
        if not matches or len(matches) < 1:
            print(f"âŒ åŒ¹é…æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆ: {matches}")
            return {
                'accuracy': default_accuracy,
                'match_count': 0,
                'total_matches': 0,
                'use_perspective_label': use_perspective_label,
                'perspective_available': perspective_available
            }

        filename = os.path.basename(match_file_path)
        if 'x' not in filename:
            print(f"âŒ æ–‡ä»¶åæ— æ³•è¯†åˆ« patch size: {filename}")
            return {
                'accuracy': default_accuracy,
                'match_count': 0,
                'total_matches': total_matches,
                'use_perspective_label': use_perspective_label,
                'perspective_available': perspective_available
            }

        patch_size = int(filename.split('x')[0])
        res = get_video_resolution_from_match_path(match_file_path)
        if res is None:
            print(f"âŒ æ— æ³•è·å–è§†é¢‘åˆ†è¾¨ç‡: {match_file_path}")
            return {
                'accuracy': default_accuracy,
                'match_count': 0,
                'total_matches': total_matches,
                'use_perspective_label': use_perspective_label,
                'perspective_available': perspective_available
            }
        width, height = res

        # è®¡ç®—çœŸå®åæ ‡
        src_pts = np.array([patch_id_to_coords(m[0], patch_size, width) for m in matches])
        dst_pts = np.array([patch_id_to_coords(m[1], patch_size, width) for m in matches])

        # æ£€æŸ¥åŒ¹é…ç‚¹æ•°é‡æ˜¯å¦è¶³å¤Ÿè¿›è¡ŒRANSAC
        if len(matches) < 4:
            print(f"âš ï¸ åŒ¹é…ç‚¹æ•°é‡ä¸è¶³({len(matches)}<4)ï¼Œè·³è¿‡RANSACï¼Œç›´æ¥è®¡ç®—å‡†ç¡®ç‡: {match_file_path}")
            # ç›´æ¥ä½¿ç”¨æ‰€æœ‰åŒ¹é…ç‚¹
            inlier_src = src_pts
            inlier_dst = dst_pts
            match_count = len(src_pts)
        else:
            ransac_threshold = max(3.0, patch_size * 0.5)  # åŠ¨æ€é˜ˆå€¼
            max_iters = 2000  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            confidence = 0.95  # ç½®ä¿¡åº¦

            # è®¡ç®—å•åº”æ€§çŸ©é˜µ
            H, mask = cv2.findHomography(
                src_pts, dst_pts,
                method=cv2.RANSAC,
                ransacReprojThreshold=ransac_threshold,
                maxIters=max_iters,
                confidence=confidence
            )

            # # ä½¿ç”¨å•ä½çŸ©é˜µï¼Œå³ä¸è¿›è¡Œä»»ä½•å˜æ¢
            # transformed_pts = src_pts  # å› ä¸º H = I

            if mask is None:
                print(f"âš ï¸ RANSAC è¿”å›æ— æ•ˆ maskï¼Œä½¿ç”¨æ‰€æœ‰åŒ¹é…ç‚¹è®¡ç®—å‡†ç¡®ç‡: {match_file_path}")
                # å½“RANSACå¤±è´¥æ—¶ï¼Œä½¿ç”¨æ‰€æœ‰åŸå§‹åŒ¹é…ç‚¹ï¼ˆä¸è¿›è¡Œè¿‡æ»¤ï¼‰
                inlier_src = src_pts
                inlier_dst = dst_pts
                match_count = len(src_pts)  # æ‰€æœ‰åŒ¹é…ç‚¹éƒ½ç®—ä½œæœ‰æ•ˆåŒ¹é…
            else:
                # æå–å†…ç‚¹å¹¶è®¡ç®—æœ‰æ•ˆåŒ¹é…æ•°
                inlier_mask = mask.ravel() == 1
                inlier_src = src_pts[inlier_mask]
                inlier_dst = dst_pts[inlier_mask]
                match_count = len(inlier_src)  # RANSACå‰”é™¤åçš„æœ‰æ•ˆåŒ¹é…æ•°

        # è®¡ç®—è¯¯å·®
        if use_perspective_label and perspective_available:
            # ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾è®¡ç®—è¯¯å·®
            print(f"ğŸ“ ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾è®¡ç®—å‡†ç¡®æ€§")
            # å°†ç¬¬ä¸€ä¸ªæ¨¡æ€çš„ç‚¹é€šè¿‡ç›¸å¯¹å˜æ¢çŸ©é˜µå˜æ¢åˆ°ç¬¬äºŒä¸ªæ¨¡æ€
            inlier_src_homogeneous = np.hstack([inlier_src, np.ones((len(inlier_src), 1))])
            transformed_pts = (relative_transform_matrix @ inlier_src_homogeneous.T).T
            # å½’ä¸€åŒ–é½æ¬¡åæ ‡
            transformed_pts = transformed_pts[:, :2] / transformed_pts[:, 2:]
            
            if not use_pt_level:
                # æ¬§å‡ é‡Œå¾—è¯¯å·®ï¼šå˜æ¢åçš„ç‚¹ä¸ç›®æ ‡ç‚¹çš„è·ç¦»
                errors = np.linalg.norm(transformed_pts - inlier_dst, axis=1)
            else:
                # æœ€å¤§å€¼è¯¯å·® (max of dx, dy)
                dx = np.abs(transformed_pts[:, 0] - inlier_dst[:, 0])
                dy = np.abs(transformed_pts[:, 1] - inlier_dst[:, 1])
                errors = np.maximum(dx, dy)
        else:
            # ä¼ ç»Ÿæ–¹æ³•ï¼šå‡è®¾è§†è§’ä¸€è‡´ï¼Œç›´æ¥æ¯”è¾ƒå¯¹åº”ç‚¹
            if not use_pt_level:
                # æ¬§å‡ é‡Œå¾—è¯¯å·®
                errors = np.linalg.norm(inlier_src - inlier_dst, axis=1)
            else:
                # æœ€å¤§å€¼è¯¯å·® (max of dx, dy)
                dx = np.abs(inlier_src[:, 0] - inlier_dst[:, 0])
                dy = np.abs(inlier_src[:, 1] - inlier_dst[:, 1])
                errors = np.maximum(dx, dy)

        total = len(errors)
        acc_by_thresh = {}
        for thresh in thresholds:
            inliers = np.sum(errors <= thresh)
            acc_by_thresh[thresh] = inliers / total if total > 0 else 0.0

        if sum(acc_by_thresh.values()) == 0:
            # æ­£ç¡®åŒ¹é…è¿‡å°‘ï¼Œè®¡ç®—çš„ransac é€è§†çŸ©é˜µä¸å¯¹ï¼Œç­›é€‰å‡ºæ¥çš„inlier point å…¶å®æ˜¯é”™è¯¯çš„
            print(f"âŒ æ‰€æœ‰é˜ˆå€¼ä¸‹çš„å‡†ç¡®ç‡éƒ½ä¸º0: {acc_by_thresh}; Match count: {match_count}; Total matches: {total_matches}")
            inlier_src = src_pts
            inlier_dst = dst_pts
            match_count = len(src_pts)

            # é‡æ–°è®¡ç®—è¯¯å·®ï¼Œè¿™æ¬¡ä¹Ÿè¦è€ƒè™‘é€è§†å˜æ¢æ ‡ç­¾
            if use_perspective_label and perspective_available:
                # ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾è®¡ç®—è¯¯å·®
                print(f"ğŸ“ ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾é‡æ–°è®¡ç®—å‡†ç¡®æ€§")
                inlier_src_homogeneous = np.hstack([inlier_src, np.ones((len(inlier_src), 1))])
                transformed_pts = (relative_transform_matrix @ inlier_src_homogeneous.T).T
                transformed_pts = transformed_pts[:, :2] / transformed_pts[:, 2:]
                
                if not use_pt_level:
                    errors = np.linalg.norm(transformed_pts - inlier_dst, axis=1)
                else:
                    dx = np.abs(transformed_pts[:, 0] - inlier_dst[:, 0])
                    dy = np.abs(transformed_pts[:, 1] - inlier_dst[:, 1])
                    errors = np.maximum(dx, dy)
            else:
                if not use_pt_level:
                    errors = np.linalg.norm(inlier_src - inlier_dst, axis=1)
                else:
                    dx = np.abs(inlier_src[:, 0] - inlier_dst[:, 0])
                    dy = np.abs(inlier_src[:, 1] - inlier_dst[:, 1])
                    errors = np.maximum(dx, dy)

            total = len(errors)
            acc_by_thresh = {}
            for thresh in thresholds:
                inliers = np.sum(errors <= thresh)
                acc_by_thresh[thresh] = inliers / total if total > 0 else 0.0


        return {
            'accuracy': acc_by_thresh,
            'match_count': match_count,
            'total_matches': total_matches,
            'use_perspective_label': use_perspective_label,
            'perspective_available': perspective_available
        }

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {match_file_path} - {str(e)}")
        return {
            'accuracy': default_accuracy,
            'match_count': 0,
            'total_matches': 0,
            'use_perspective_label': use_perspective_label,
            'perspective_available': perspective_available
        }


class MatchResultAnalyzer:
    def __init__(self, output_dir: str, exclude_modalities: List[str] = None, scene_prefix: str = 'V', 
                 use_perspective_label: bool = False):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            output_dir: MultiModal_Output_ransac_5_05 ç›®å½•è·¯å¾„
            exclude_modalities: è¦æ’é™¤çš„æ¨¡æ€åˆ—è¡¨ï¼Œä¾‹å¦‚ ['OpticalFlow', 'FreqDomain']
            scene_prefix: åœºæ™¯æ–‡ä»¶å¤¹å‰ç¼€ï¼Œä¾‹å¦‚ 'V', 'A', 'K' ç­‰
            use_perspective_label: æ˜¯å¦ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾è®¡ç®—å‡†ç¡®æ€§
        """
        self.output_dir = output_dir
        self.exclude_modalities = exclude_modalities or []
        self.scene_prefix = scene_prefix
        self.use_perspective_label = use_perspective_label
        self.scenarios = []
        self.modality_pairs = []
        self.grid_sizes = ['8x8', '16x16', '32x32', '64x64']
        
        # å­˜å‚¨æ‰€æœ‰ç»Ÿè®¡ç»“æœ
        self.scenario_modality_results = defaultdict(lambda: defaultdict(dict))  # scenario -> modality_pair -> grid_size -> result_dict
        self.scenario_averages = defaultdict(dict)  # scenario -> grid_size -> average_accuracy
        self.modality_averages = defaultdict(dict)  # modality_pair -> grid_size -> average_accuracy
        self.global_averages = {}  # grid_size -> average_accuracy
        
        # æ–°å¢ï¼šå­˜å‚¨åŒ¹é…æ•°ç»Ÿè®¡ç»“æœ
        self.scenario_match_counts = defaultdict(lambda: defaultdict(dict))  # scenario -> modality_pair -> grid_size -> match_count
        self.scenario_match_averages = defaultdict(dict)  # scenario -> grid_size -> average_match_count
        self.modality_match_averages = defaultdict(dict)  # modality_pair -> grid_size -> average_match_count
        self.global_match_averages = {}  # grid_size -> average_match_count
        
    def _should_exclude_modality_pair(self, modality_pair: str) -> bool:
        """
        æ£€æŸ¥æ¨¡æ€é…å¯¹æ˜¯å¦åº”è¯¥è¢«æ’é™¤
        
        Args:
            modality_pair: æ¨¡æ€é…å¯¹åç§°ï¼Œå¦‚ 'FreqDomain_vs_OpticalFlow'
            
        Returns:
            True å¦‚æœåº”è¯¥æ’é™¤ï¼ŒFalse å¦‚æœåº”è¯¥ä¿ç•™
        """
        if not self.exclude_modalities:
            return False
        
        # æ£€æŸ¥æ¨¡æ€é…å¯¹ä¸­æ˜¯å¦åŒ…å«ä»»ä½•éœ€è¦æ’é™¤çš„æ¨¡æ€
        for exclude_modality in self.exclude_modalities:
            if exclude_modality in modality_pair:
                return True
        
        return False

    def scan_directory_structure(self):
        """æ‰«æç›®å½•ç»“æ„ï¼Œè·å–æ‰€æœ‰åœºæ™¯å’Œæ¨¡æ€é…å¯¹"""
        self.scenarios = []
        self.modality_pairs = set()
        
        for item in os.listdir(self.output_dir):
            if os.path.isdir(os.path.join(self.output_dir, item)) and item.startswith(self.scene_prefix):
                self.scenarios.append(item)
                
                # æ‰«æè¯¥åœºæ™¯ä¸‹çš„æ¨¡æ€é…å¯¹
                scenario_dir = os.path.join(self.output_dir, item)
                for modality_item in os.listdir(scenario_dir):
                    modality_path = os.path.join(scenario_dir, modality_item)
                    if os.path.isdir(modality_path) and '_vs_' in modality_item:
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’é™¤è¯¥æ¨¡æ€é…å¯¹
                        if not self._should_exclude_modality_pair(modality_item):
                            self.modality_pairs.add(modality_item)
        
        self.scenarios.sort(key=lambda x: int(x[1:]))  # æŒ‰æ•°å­—æ’åº
        self.modality_pairs = sorted(list(self.modality_pairs))
        
        print(f"å‘ç° {len(self.scenarios)} ä¸ªåœºæ™¯: {self.scenarios}")
        print(f"å‘ç° {len(self.modality_pairs)} ä¸ªæ¨¡æ€é…å¯¹: {self.modality_pairs}")
        
        if self.exclude_modalities:
            print(f"å·²æ’é™¤åŒ…å«ä»¥ä¸‹æ¨¡æ€çš„é…å¯¹: {self.exclude_modalities}")
    
    def find_match_files(self, scenario: str, modality_pair: str) -> Dict[str, str]:
        """
        æ‰¾åˆ°æŒ‡å®šåœºæ™¯å’Œæ¨¡æ€é…å¯¹çš„åŒ¹é…ç»“æœæ–‡ä»¶
        
        Args:
            scenario: åœºæ™¯åç§°ï¼Œå¦‚ 'K1'
            modality_pair: æ¨¡æ€é…å¯¹åç§°ï¼Œå¦‚ 'FreqDomain_vs_MotionThermal'
            
        Returns:
            å­—å…¸ï¼Œé”®ä¸ºç½‘æ ¼å¤§å°ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„
        """
        match_files = {}
        
        # æ„å»ºè·¯å¾„ï¼šscenario/modality_pair/MatchResult/List/å­æ–‡ä»¶å¤¹/
        base_path = os.path.join(self.output_dir, scenario, modality_pair, 'MatchResult', 'List')
        
        if not os.path.exists(base_path):
            return match_files
        
        # æ‰¾åˆ°Listä¸‹çš„å­æ–‡ä»¶å¤¹ï¼ˆæ— æ„ä¹‰çš„å±‚çº§æ–‡ä»¶å¤¹ï¼‰
        try:
            subdirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
            if not subdirs:
                return match_files
            
            # å–ç¬¬ä¸€ä¸ªå­æ–‡ä»¶å¤¹
            subdir = subdirs[0]
            match_dir = os.path.join(base_path, subdir)
            
            # å¯»æ‰¾ç½‘æ ¼å¤§å°æ–‡ä»¶
            for grid_size in self.grid_sizes:
                file_path = os.path.join(match_dir, f"{grid_size}.txt")
                if os.path.exists(file_path):
                    match_files[grid_size] = file_path
                    
        except Exception as e:
            print(f"Error scanning {base_path}: {e}")
        
        return match_files
    
    def analyze_scenario_modality(self, scenario: str, modality_pair: str):
        """åˆ†æç‰¹å®šåœºæ™¯å’Œæ¨¡æ€é…å¯¹çš„ç»“æœ"""
        match_files = self.find_match_files(scenario, modality_pair)
        
        for grid_size, file_path in match_files.items():
            result_dict = calculate_accuracy(file_path, self.use_perspective_label)
            
            # å­˜å‚¨å®Œæ•´ç»“æœ
            self.scenario_modality_results[scenario][modality_pair][grid_size] = result_dict
            
            # å•ç‹¬å­˜å‚¨åŒ¹é…æ•°ä¿¡æ¯
            self.scenario_match_counts[scenario][modality_pair][grid_size] = {
                'match_count': result_dict['match_count'],
                'total_matches': result_dict['total_matches'],
                'retention_rate': result_dict['match_count'] / result_dict['total_matches'] if result_dict['total_matches'] > 0 else 0.0
            }
            
            print(f"  {scenario} - {modality_pair} - {grid_size}:")
            print(f"    å‡†ç¡®ç‡: {result_dict['accuracy']}")
            print(f"    åŒ¹é…æ•°: {result_dict['match_count']}/{result_dict['total_matches']} "
                  f"(ä¿ç•™ç‡: {self.scenario_match_counts[scenario][modality_pair][grid_size]['retention_rate']:.2%})")
    
    def calculate_scenario_averages(self):
        """è®¡ç®—æ¯ä¸ªåœºæ™¯æ‰€æœ‰æ¨¡æ€åŒ¹é…ç»“æœçš„ä¸åŒç½‘æ ¼å¤§å°å¹³å‡å‡†ç¡®ç‡"""
        for scenario in self.scenarios:
            for grid_size in self.grid_sizes:
                acc_by_thresh = defaultdict(list)  # æ¯ä¸ªåƒç´ é˜ˆå€¼ -> æ‰€æœ‰æ¨¡æ€å‡†ç¡®ç‡åˆ—è¡¨
                match_counts = []  # åŒ¹é…æ•°åˆ—è¡¨

                for modality_pair in self.modality_pairs:
                    result_dict = self.scenario_modality_results.get(scenario, {}).get(modality_pair, {}).get(grid_size)
                    if result_dict and 'accuracy' in result_dict:
                        acc_dict = result_dict['accuracy']
                        for thresh, acc in acc_dict.items():
                            acc_by_thresh[thresh].append(acc)
                        
                        # æ”¶é›†åŒ¹é…æ•°
                        match_counts.append(result_dict['match_count'])

                # è®¡ç®—æ¯ä¸ªåƒç´ é˜ˆå€¼çš„å¹³å‡å‡†ç¡®ç‡
                if acc_by_thresh:
                    self.scenario_averages[scenario][grid_size] = {
                        thresh: sum(accs) / len(accs) for thresh, accs in acc_by_thresh.items()
                    }
                
                # è®¡ç®—å¹³å‡åŒ¹é…æ•°
                if match_counts:
                    self.scenario_match_averages[scenario][grid_size] = sum(match_counts) / len(match_counts)

    
    def calculate_modality_averages(self):
        """è®¡ç®—æ¯ä¸ªæ¨¡æ€åœ¨æ‰€æœ‰åœºæ™¯ä¸‹çš„ä¸åŒç½‘æ ¼å¤§å°å¹³å‡å‡†ç¡®ç‡"""
        for modality_pair in self.modality_pairs:
            for grid_size in self.grid_sizes:
                acc_by_thresh = defaultdict(list)
                match_counts = []

                for scenario in self.scenarios:
                    result_dict = self.scenario_modality_results.get(scenario, {}).get(modality_pair, {}).get(grid_size)
                    if result_dict and 'accuracy' in result_dict:
                        acc_dict = result_dict['accuracy']
                        for thresh, acc in acc_dict.items():
                            acc_by_thresh[thresh].append(acc)
                        
                        # æ”¶é›†åŒ¹é…æ•°
                        match_counts.append(result_dict['match_count'])

                if acc_by_thresh:
                    self.modality_averages[modality_pair][grid_size] = {
                        thresh: sum(accs) / len(accs) for thresh, accs in acc_by_thresh.items()
                    }
                
                # è®¡ç®—å¹³å‡åŒ¹é…æ•°
                if match_counts:
                    self.modality_match_averages[modality_pair][grid_size] = sum(match_counts) / len(match_counts)

    
    def calculate_global_averages(self):
        """è®¡ç®—æ‰€æœ‰åœºæ™¯çš„ä¸åŒç½‘æ ¼å¹³å‡å‡†ç¡®ç‡ï¼ˆæ¯ä¸ªåƒç´ é˜ˆå€¼ï¼‰"""
        for grid_size in self.grid_sizes:
            acc_by_thresh = defaultdict(list)
            match_counts = []

            for scenario in self.scenarios:
                for modality_pair in self.modality_pairs:
                    result_dict = self.scenario_modality_results.get(scenario, {}).get(modality_pair, {}).get(grid_size)
                    if result_dict and 'accuracy' in result_dict:
                        acc_dict = result_dict['accuracy']
                        for thresh, acc in acc_dict.items():
                            acc_by_thresh[thresh].append(acc)
                        
                        # æ”¶é›†åŒ¹é…æ•°
                        match_counts.append(result_dict['match_count'])

            if acc_by_thresh:
                self.global_averages[grid_size] = {
                    thresh: sum(accs) / len(accs) for thresh, accs in acc_by_thresh.items()
                }
            
            # è®¡ç®—å…¨å±€å¹³å‡åŒ¹é…æ•°
            if match_counts:
                self.global_match_averages[grid_size] = sum(match_counts) / len(match_counts)

    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("å¼€å§‹åˆ†æåŒ¹é…ç»“æœ...")
        
        # 1. æ‰«æç›®å½•ç»“æ„
        self.scan_directory_structure()
        
        # 2. åˆ†ææ¯ä¸ªåœºæ™¯çš„æ¯ä¸ªæ¨¡æ€é…å¯¹
        print("\næ­£åœ¨åˆ†æå„åœºæ™¯å’Œæ¨¡æ€é…å¯¹çš„å‡†ç¡®ç‡...")
        for scenario in self.scenarios:
            print(f"åˆ†æåœºæ™¯ {scenario}:")
            for modality_pair in self.modality_pairs:
                self.analyze_scenario_modality(scenario, modality_pair)
        
        # 3. è®¡ç®—å„ç§å¹³å‡å€¼
        print("\nè®¡ç®—åœºæ™¯å¹³å‡å‡†ç¡®ç‡...")
        self.calculate_scenario_averages()
        
        print("è®¡ç®—æ¨¡æ€å¹³å‡å‡†ç¡®ç‡...")
        self.calculate_modality_averages()
        
        print("è®¡ç®—å…¨å±€å¹³å‡å‡†ç¡®ç‡...")
        self.calculate_global_averages()
        
        print("\nåˆ†æå®Œæˆï¼")
    
    def save_results_to_excel(self, output_file: str = "match_results_analysis.xlsx"):
        """å°†ç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶"""
        # å¦‚æœæœ‰æ’é™¤æ¨¡æ€ï¼Œåœ¨æ–‡ä»¶åä¸­ä½“ç°
        if self.exclude_modalities:
            base_name, ext = os.path.splitext(output_file)
            excluded_str = "_excluded_" + "_".join(self.exclude_modalities)
            output_file = f"{base_name}{excluded_str}{ext}"
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 1. æ¯ä¸ªåœºæ™¯æ¯ä¸ªæ¨¡æ€çš„è¯¦ç»†ç»“æœï¼ˆå‡†ç¡®ç‡ï¼‰
            detailed_data = []
            for scenario in self.scenarios:
                for modality_pair in self.modality_pairs:
                    if scenario in self.scenario_modality_results and modality_pair in self.scenario_modality_results[scenario]:
                        row_data = {'åœºæ™¯': scenario, 'æ¨¡æ€é…å¯¹': modality_pair}
                        for grid_size in self.grid_sizes:
                            if grid_size in self.scenario_modality_results[scenario][modality_pair]:
                                result_dict = self.scenario_modality_results[scenario][modality_pair][grid_size]
                                row_data[f'å‡†ç¡®ç‡_{grid_size}'] = result_dict.get('accuracy', None)
                            else:
                                row_data[f'å‡†ç¡®ç‡_{grid_size}'] = None
                        detailed_data.append(row_data)
            
            detailed_df = pd.DataFrame(detailed_data)
            detailed_df.to_excel(writer, sheet_name='è¯¦ç»†ç»“æœ_å‡†ç¡®ç‡', index=False)
            
            # 1.5. æ¯ä¸ªåœºæ™¯æ¯ä¸ªæ¨¡æ€çš„åŒ¹é…æ•°è¯¦ç»†ç»“æœ
            match_count_data = []
            for scenario in self.scenarios:
                for modality_pair in self.modality_pairs:
                    if scenario in self.scenario_match_counts and modality_pair in self.scenario_match_counts[scenario]:
                        row_data = {'åœºæ™¯': scenario, 'æ¨¡æ€é…å¯¹': modality_pair}
                        for grid_size in self.grid_sizes:
                            if grid_size in self.scenario_match_counts[scenario][modality_pair]:
                                match_info = self.scenario_match_counts[scenario][modality_pair][grid_size]
                                row_data[f'æœ‰æ•ˆåŒ¹é…æ•°_{grid_size}'] = match_info['match_count']
                                row_data[f'æ€»åŒ¹é…æ•°_{grid_size}'] = match_info['total_matches']
                                row_data[f'ä¿ç•™ç‡_{grid_size}'] = f"{match_info['retention_rate']:.2%}"
                            else:
                                row_data[f'æœ‰æ•ˆåŒ¹é…æ•°_{grid_size}'] = None
                                row_data[f'æ€»åŒ¹é…æ•°_{grid_size}'] = None
                                row_data[f'ä¿ç•™ç‡_{grid_size}'] = None
                        match_count_data.append(row_data)
            
            match_count_df = pd.DataFrame(match_count_data)
            match_count_df.to_excel(writer, sheet_name='è¯¦ç»†ç»“æœ_åŒ¹é…æ•°', index=False)
            
            # 2. åœºæ™¯å¹³å‡å‡†ç¡®ç‡
            scenario_avg_data = []
            for scenario in self.scenarios:
                if scenario in self.scenario_averages:
                    row_data = {'åœºæ™¯': scenario}
                    for grid_size in self.grid_sizes:
                        if grid_size in self.scenario_averages[scenario]:
                            row_data[f'å¹³å‡å‡†ç¡®ç‡_{grid_size}'] = self.scenario_averages[scenario][grid_size]
                        else:
                            row_data[f'å¹³å‡å‡†ç¡®ç‡_{grid_size}'] = "NA"
                    scenario_avg_data.append(row_data)
            
            scenario_avg_df = pd.DataFrame(scenario_avg_data)
            scenario_avg_df.to_excel(writer, sheet_name='åœºæ™¯å¹³å‡å‡†ç¡®ç‡', index=False)
            
            # 3. æ¨¡æ€å¹³å‡å‡†ç¡®ç‡
            modality_avg_data = []
            for modality_pair in self.modality_pairs:
                if modality_pair in self.modality_averages:
                    row_data = {'æ¨¡æ€é…å¯¹': modality_pair}
                    for grid_size in self.grid_sizes:
                        if grid_size in self.modality_averages[modality_pair]:
                            row_data[f'å¹³å‡å‡†ç¡®ç‡_{grid_size}'] = self.modality_averages[modality_pair][grid_size]
                        else:
                            row_data[f'å¹³å‡å‡†ç¡®ç‡_{grid_size}'] = None
                    modality_avg_data.append(row_data)
            
            modality_avg_df = pd.DataFrame(modality_avg_data)
            modality_avg_df.to_excel(writer, sheet_name='æ¨¡æ€å¹³å‡å‡†ç¡®ç‡', index=False)
            
            # 4. å…¨å±€å¹³å‡å‡†ç¡®ç‡
            global_avg_data = [{'ç½‘æ ¼å¤§å°': grid_size, 'å…¨å±€å¹³å‡å‡†ç¡®ç‡': self.global_averages.get(grid_size, None)} 
                             for grid_size in self.grid_sizes]
            global_avg_df = pd.DataFrame(global_avg_data)
            global_avg_df.to_excel(writer, sheet_name='å…¨å±€å¹³å‡å‡†ç¡®ç‡', index=False)
            
            # 5. åœºæ™¯å¹³å‡åŒ¹é…æ•°
            scenario_match_avg_data = []
            for scenario in self.scenarios:
                if scenario in self.scenario_match_averages:
                    row_data = {'åœºæ™¯': scenario}
                    for grid_size in self.grid_sizes:
                        if grid_size in self.scenario_match_averages[scenario]:
                            row_data[f'å¹³å‡åŒ¹é…æ•°_{grid_size}'] = self.scenario_match_averages[scenario][grid_size]
                        else:
                            row_data[f'å¹³å‡åŒ¹é…æ•°_{grid_size}'] = "NA"
                    scenario_match_avg_data.append(row_data)
            
            scenario_match_avg_df = pd.DataFrame(scenario_match_avg_data)
            scenario_match_avg_df.to_excel(writer, sheet_name='åœºæ™¯å¹³å‡åŒ¹é…æ•°', index=False)
            
            # 6. æ¨¡æ€å¹³å‡åŒ¹é…æ•°
            modality_match_avg_data = []
            for modality_pair in self.modality_pairs:
                if modality_pair in self.modality_match_averages:
                    row_data = {'æ¨¡æ€é…å¯¹': modality_pair}
                    for grid_size in self.grid_sizes:
                        if grid_size in self.modality_match_averages[modality_pair]:
                            row_data[f'å¹³å‡åŒ¹é…æ•°_{grid_size}'] = self.modality_match_averages[modality_pair][grid_size]
                        else:
                            row_data[f'å¹³å‡åŒ¹é…æ•°_{grid_size}'] = None
                    modality_match_avg_data.append(row_data)
            
            modality_match_avg_df = pd.DataFrame(modality_match_avg_data)
            modality_match_avg_df.to_excel(writer, sheet_name='æ¨¡æ€å¹³å‡åŒ¹é…æ•°', index=False)
            
            # 7. å…¨å±€å¹³å‡åŒ¹é…æ•°
            global_match_avg_data = [{'ç½‘æ ¼å¤§å°': grid_size, 'å…¨å±€å¹³å‡åŒ¹é…æ•°': self.global_match_averages.get(grid_size, None)} 
                                   for grid_size in self.grid_sizes]
            global_match_avg_df = pd.DataFrame(global_match_avg_data)
            global_match_avg_df.to_excel(writer, sheet_name='å…¨å±€å¹³å‡åŒ¹é…æ•°', index=False)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ° {output_file}")
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "="*80)
        print("åŒ¹é…ç»“æœç»Ÿè®¡æ‘˜è¦")
        print("="*80)

        grid_size_key = '8x8'

        # å…¨å±€å¹³å‡å‡†ç¡®ç‡ï¼ˆ8x8ï¼‰
        print("\nã€å…¨å±€å¹³å‡å‡†ç¡®ç‡ - 8x8ã€‘")
        if grid_size_key in self.global_averages:
            print(f"  8x8: {self.global_averages[grid_size_key]}")
        
        # å…¨å±€å¹³å‡åŒ¹é…æ•°ï¼ˆ8x8ï¼‰
        print("\nã€å…¨å±€å¹³å‡åŒ¹é…æ•° - 8x8ã€‘")
        if grid_size_key in self.global_match_averages:
            print(f"  8x8: {self.global_match_averages[grid_size_key]:.1f}")

        # è·å–ç¬¬ä¸€ä¸ªé˜ˆå€¼ï¼ˆåŠ¨æ€ç¡®å®šï¼‰
        first_threshold = None
        first_threshold_name = None
        for modality, grid_data in self.modality_averages.items():
            if grid_size_key in grid_data:
                acc_dict = grid_data[grid_size_key]
                if acc_dict:
                    first_threshold = min(acc_dict.keys())  # å–æœ€å°çš„é˜ˆå€¼ä½œä¸ºç¬¬ä¸€ä¸ªé˜ˆå€¼
                    first_threshold_name = f"{first_threshold}åƒç´ "
                    break
        
        if first_threshold is None:
            print("\nâš ï¸ æ— æ³•ç¡®å®šç¬¬ä¸€ä¸ªé˜ˆå€¼ï¼Œè·³è¿‡æ¨¡æ€ç»Ÿè®¡")
        else:
            # æ¨¡æ€ç¬¬ä¸€é˜ˆå€¼å‡†ç¡®ç‡ï¼ˆæŒ‰8x8æ’åºåå‰5ä¸ªï¼‰
            print(f"\nã€æ¨¡æ€{first_threshold_name}é˜ˆå€¼å‡†ç¡®ç‡ - 8x8ï¼ˆå‰5ä¸ªï¼‰ã€‘")

            # è®¡ç®—æ¯ä¸ªæ¨¡æ€åœ¨8x8ä¸‹çš„ç¬¬ä¸€é˜ˆå€¼å‡†ç¡®ç‡
            modality_first_8x8 = []
            for modality, grid_data in self.modality_averages.items():
                if grid_size_key in grid_data:
                    acc_dict = grid_data[grid_size_key]
                    if first_threshold in acc_dict:
                        acc_first = acc_dict[first_threshold]
                        modality_first_8x8.append((modality, acc_first))
        
            # æŒ‰ç¬¬ä¸€é˜ˆå€¼å‡†ç¡®ç‡æ’åºï¼Œå–å‰5
            top5_modalities = sorted(modality_first_8x8, key=lambda x: x[1], reverse=True)[:5]
            for modality, acc in top5_modalities:
                print(f"  {modality}: {first_threshold_name}é˜ˆå€¼å‡†ç¡®ç‡ = {acc:.4f}")
                accs = self.modality_averages[modality][grid_size_key]
                for thresh, a in sorted(accs.items()):
                    print(f"    é˜ˆå€¼ {thresh}px: {a:.4f}")
                
                # æ˜¾ç¤ºå¹³å‡åŒ¹é…æ•°
                if modality in self.modality_match_averages and grid_size_key in self.modality_match_averages[modality]:
                    avg_matches = self.modality_match_averages[modality][grid_size_key]
                    print(f"    å¹³å‡åŒ¹é…æ•°: {avg_matches:.1f}")

        # åœºæ™¯ç¬¬ä¸€é˜ˆå€¼å‡†ç¡®ç‡ï¼ˆä½¿ç”¨ä¸æ¨¡æ€ç›¸åŒçš„ç¬¬ä¸€é˜ˆå€¼ï¼‰
        if first_threshold is None:
            print("\nâš ï¸ æ— æ³•ç¡®å®šç¬¬ä¸€ä¸ªé˜ˆå€¼ï¼Œè·³è¿‡åœºæ™¯ç»Ÿè®¡")
        else:
            print(f"\nã€åœºæ™¯{first_threshold_name}é˜ˆå€¼å‡†ç¡®ç‡ - 8x8ï¼ˆå‰5ä¸ªï¼‰ã€‘")

            scenario_first_8x8 = []
            for scenario, grid_data in self.scenario_averages.items():
                if grid_size_key in grid_data:
                    acc_dict = grid_data[grid_size_key]
                    if first_threshold in acc_dict:
                        acc_first = acc_dict[first_threshold]
                        scenario_first_8x8.append((scenario, acc_first))

            # æŒ‰ç¬¬ä¸€é˜ˆå€¼å‡†ç¡®ç‡æ’åºï¼Œå–å‰5
            top5_scenarios = sorted(scenario_first_8x8, key=lambda x: x[1], reverse=True)[:5]
            for scenario, acc in top5_scenarios:
                print(f"  {scenario}: {first_threshold_name}é˜ˆå€¼å‡†ç¡®ç‡ = {acc:.4f}")
                accs = self.scenario_averages[scenario][grid_size_key]
                for thresh, a in sorted(accs.items()):
                    print(f"    é˜ˆå€¼ {thresh}px: {a:.4f}")
                
                # æ˜¾ç¤ºå¹³å‡åŒ¹é…æ•°
                if scenario in self.scenario_match_averages and grid_size_key in self.scenario_match_averages[scenario]:
                    avg_matches = self.scenario_match_averages[scenario][grid_size_key]
                    print(f"    å¹³å‡åŒ¹é…æ•°: {avg_matches:.1f}")

        print("\nè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ç”Ÿæˆçš„Excelæ–‡ä»¶ã€‚")
        print("æ–°å¢åŠŸèƒ½ï¼šç°åœ¨åŒ…å«RANSACç®—æ³•å‰”é™¤åçš„åŒ¹é…æ•°ç»Ÿè®¡ï¼")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='å¤šæ¨¡æ€åŒ¹é…ç»“æœå‡†ç¡®ç‡ç»Ÿè®¡è„šæœ¬')
    parser.add_argument('--output_dir', 
                       default="/media/jackew/Extreme SSD/newData/MultiModal_Output",
                       help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: /media/jackew/Extreme SSD/newData/MultiModal_Output)')
    parser.add_argument('--exclude_modalities', 
                       nargs='*', 
                       default=[],
                       help='è¦æ’é™¤çš„æ¨¡æ€åˆ—è¡¨ï¼Œä¾‹å¦‚: --exclude_modalities OpticalFlow FreqDomain')
    parser.add_argument('--excel_output',
                       default="match_results_analysis.xlsx",
                       help='Excelè¾“å‡ºæ–‡ä»¶å (é»˜è®¤: match_results_analysis.xlsx)')
    parser.add_argument('--scene_prefix',
                       default='V',
                       help='åœºæ™¯æ–‡ä»¶å¤¹å‰ç¼€ï¼Œä¾‹å¦‚ V, A, K ç­‰ (é»˜è®¤: V)')
    parser.add_argument('--use_perspective_label',
                       action='store_true',
                       help='ä½¿ç”¨é€è§†å˜æ¢æ ‡ç­¾çŸ©é˜µè®¡ç®—å‡†ç¡®æ€§ï¼ˆç”¨äºé€è§†å˜æ¢å¢å¼ºçš„æ•°æ®ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºç›®å½•è·¯å¾„
    output_dir = args.output_dir
    
    if not os.path.exists(output_dir):
        print(f"é”™è¯¯ï¼šè¾“å‡ºç›®å½•ä¸å­˜åœ¨ - {output_dir}")
        return
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("="*80)
    print("å¤šæ¨¡æ€åŒ¹é…ç»“æœåˆ†æé…ç½®")
    print("="*80)
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"æ’é™¤æ¨¡æ€: {args.exclude_modalities if args.exclude_modalities else 'æ— '}")
    print(f"Excelè¾“å‡º: {args.excel_output}")
    print(f"åœºæ™¯å‰ç¼€: {args.scene_prefix}")
    print(f"é€è§†å˜æ¢æ ‡ç­¾: {'å¯ç”¨' if args.use_perspective_label else 'ç¦ç”¨'}")
    if args.use_perspective_label:
        print("  âš ï¸ æ³¨æ„ï¼šå¯ç”¨é€è§†å˜æ¢æ ‡ç­¾éœ€è¦ç›¸å¯¹å˜æ¢çŸ©é˜µæ–‡ä»¶ (relative_transform_matrix.npy)")
    print("="*80)
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œåˆ†æ
    analyzer = MatchResultAnalyzer(output_dir, exclude_modalities=args.exclude_modalities, 
                                 scene_prefix=args.scene_prefix, use_perspective_label=args.use_perspective_label)
    analyzer.run_analysis()
    
    # ä¿å­˜ç»“æœå¹¶æ‰“å°æ‘˜è¦
    analyzer.save_results_to_excel(args.excel_output)
    analyzer.print_summary()

if __name__ == "__main__":
    main()
